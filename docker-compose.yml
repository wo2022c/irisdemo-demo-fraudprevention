
#volumes:
#  common_shared:

services:

  datalake:
    init: true
    image: intersystemsdc/irisdemo-demo-fraudprevention:datalake-version-1.13.0
    hostname: datalake
    restart: on-failure
    command: --check-caps false
    ports:
    # 1972 is the superserver default port
    - "9095:1972"
    # 52773 is the webserver/management portal port
    - "9094:52773"
    volumes:
    - type: bind
      source: ./normalized_datalake/shared/
      target: /shared

  bankingcore:
    init: true
    image: intersystemsdc/irisdemo-demo-fraudprevention:bankingcore-version-1.13.0
    hostname: bankingcore
    command: --check-caps false
    ports:
    # 1972 is the superserver default port
    - "9091:1972"
    # 52773 is the webserver/management portal port
    - "9090:52773"
    volumes:
    - type: bind
      source: ./banking_core/shared/
      target: /shared

  bankingtrnsrv:
    image: intersystemsdc/irisdemo-demo-fraudprevention:bankingtrnsrv-version-1.13.0
    hostname: bankingtrnsrv
    command: --check-caps false
    init: true
    ports:
    # 1972 is the superserver default port
    - "9093:1972"
    # 52773 is the webserver/management portal port
    - "9092:52773"
    volumes:
    - type: bind
      source: ./common_shared/
      target: /common_shared   # The production will be looking into this folder for new PMML files
                                       # that will be sent by the advancedanalytics service.
    - type: bind
      source: ./banking_trn_srv/shared/
      target: /shared

  pos:
    image: intersystemsdc/irisdemo-demo-fraudprevention:pos-version-1.13.0
    init: true
    ports:
      - "9099:4200"
    working_dir: /home/node/app
    environment:
      - NODE_ENV=production
      - OVERRID_BANKINGTRNSRV_HOST=
    command: "sh -c 'npm install && npm run proxy'"
    volumes:
      - ./pos/app/src:/home/node/app/src
      - ./pos/app/proxy.config.json:/home/node/app/proxy.config.json


  # advancedanalytics:
  #   image: intersystemsdc/irisdemo-base-zeppelin:version-1.3
  #   init: true
  #   ports:
  #   - "9096:9090"   # Zeppelin
  #   - 4141:4040     # Zeppelin Spark UI
  #   volumes:
  #   - type: bind
  #     source: ./common_shared/
  #     target: /common_shared   # The production will be looking into this folder for new PMML files
  #                                      # that will be sent by the advancedanalytics service.
  #   - type: bind
  #     source: ./advanced_analytics/shared/
  #     target: /shared
  #   environment:
  #   - IRIS_MASTER_HOST=datalake # DNS based on the name of the service!
  #   - IRIS_MASTER_PORT=1972 
  #   - IRIS_MASTER_USERNAME=SuperUser 
  #   - IRIS_MASTER_PASSWORD=sys 
  #   - IRIS_MASTER_NAMESPACE=APP 

  # sparkmaster:
  #   image: intersystemsdc/irisdemo-base-spark-iris:version-1.2.3
  #   hostname: sparkmaster # Must be always sparkmaster
  #   init: true
  #   environment:
  #     SPARK_NODE_TYPE: Master
  #     SPARK_PUBLIC_DNS: localhost
  #     IRIS_MASTER_HOST: datalake # DNS based on the name of the service!
  #     IRIS_MASTER_PORT: 1972 
  #     IRIS_MASTER_USERNAME: SuperUser 
  #     IRIS_MASTER_PASSWORD: sys 
  #     IRIS_MASTER_NAMESPACE: APP 
  #   ports:
  #     - 4040:4040
  #     - 6066:6066
  #     - 7077:7077
  #     - 8080:8080   # Spark Master Portal
  #   volumes:
  #   - type: bind
  #     source: ./common_shared/
  #     target: /common_shared   # Shared between all spark nodes. Good place to place a file we are working with.

  # worker1:
  #   depends_on: 
  #     - sparkmaster
  #   image: intersystemsdc/irisdemo-base-spark-iris:version-1.2.3
  #   hostname: worker1
  #   init: true
  #   environment:
  #     IRIS_MASTER_HOST: datalake # DNS based on the name of the service!
  #     IRIS_MASTER_PORT: 1972 
  #     IRIS_MASTER_USERNAME: SuperUser 
  #     IRIS_MASTER_PASSWORD: sys 
  #     IRIS_MASTER_NAMESPACE: APP 

  #     SPARK_NODE_TYPE: Worker
  #     SPARK_WORKER_CORES: 1
  #     SPARK_WORKER_MEMORY: 1g   # You can give more memory to your work if you are getting errors when using Spark
  #     SPARK_WORKER_PORT: 8881
  #     SPARK_WORKER_WEBUI_PORT: 8081
  #     SPARK_PUBLIC_DNS: localhost
  #   ports:
  #     - 8081:8081   # Spark Worker Portal
  #   volumes:
  #   - type: bind
  #     source: ./common_shared/
  #     target: /common_shared   # Shared between all spark nodes. Good place to place a file we are working with.  

  # worker2:
  #   depends_on: 
  #     - sparkmaster
  #   image: intersystemsdc/irisdemo-base-spark-iris:version-1.2.3
  #   hostname: worker2
  #   init: true
  #   environment:
  #     IRIS_MASTER_HOST: datalake # DNS based on the name of the service!
  #     IRIS_MASTER_PORT: 1972 
  #     IRIS_MASTER_USERNAME: SuperUser 
  #     IRIS_MASTER_PASSWORD: sys 
  #     IRIS_MASTER_NAMESPACE: APP 

  #     SPARK_NODE_TYPE: Worker
  #     SPARK_WORKER_CORES: 1
  #     SPARK_WORKER_MEMORY: 1g   # You can give more memory to your work if you are getting errors when using Spark
  #     SPARK_WORKER_PORT: 8882
  #     SPARK_WORKER_WEBUI_PORT: 8082
  #     SPARK_PUBLIC_DNS: localhost
  #   ports:
  #     - 8082:8082   # Spark Worker Portal
  #   volumes:
  #   - type: bind
  #     source: ./common_shared/
  #     target: /common_shared   # Shared between all spark nodes. Good place to place a file we are working with.

  transgen:
    build: 
      context: .
      dockerfile: mock-transaction/Dockerfile
    container_name: transgen
    depends_on:
      - datalake
    volumes:
      - ./mock-transaction/mock-generator:/workspace


  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./servers_mntring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9190:9090"
    depends_on:
      - datalake
    restart: always

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=secret123
    volumes:
      - ./servers_mntring/grafana/provisioning:/etc/grafana/provisioning
      - ./servers_mntring/grafana/dashboards/dashboards.yml:/etc/grafana/provisioning/dashboards/main.yaml
      - ./servers_mntring/grafana/dashboards:/var/lib/grafana/dashboards
    depends_on:
      - prometheus  

  superset:
    build:
      context: .
      dockerfile: superset/Dockerfile
    ports:
      - 8088:8088
    environment:
      - SUPERSET_SECRET_KEY=someverysecretrandomkey
      - SUPERSET_PUBLIC_ROLE_LIKE=Alpha
      - SUPERSET_SQLALCHEMY_EXAMPLES_URI=iris://_system:sys@datalake:1972/APP
    depends_on:
      - datalake
    volumes:
      # persisted dashboards and charts
      - ./superset/superset_home:/app/pythonpath/superset_home
      # configuration files
      - ./superset/superset_config:/app/pythonpath/superset_config
      - ./superset/.superset:/root/.superset/
